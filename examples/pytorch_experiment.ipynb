{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VisLogger PyTorch Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from vislogger import Config\n",
    "from vislogger.experiment import PyTorchExperiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180322-130949_experiment  data\t     test-experiment2\n",
      "20180322-131011_experiment  test-experiment\n"
     ]
    }
   ],
   "source": [
    "!ls experiment_dir/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf experiment_dir/20*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107M\texperiment_dir/\n"
     ]
    }
   ],
   "source": [
    "!du -sh experiment_dir/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Config()\n",
    "\n",
    "c.batch_size = 64\n",
    "c.batch_size_test = 1000\n",
    "c.n_epochs = 10\n",
    "c.learning_rate = 0.01\n",
    "c.momentum = 0.9\n",
    "if torch.cuda.is_available():\n",
    "    c.use_cuda = True\n",
    "else:\n",
    "    c.use_cuda = False\n",
    "c.data_loader_kwargs = {'num_workers': 1, 'pin_memory': True} if c.use_cuda else {}\n",
    "c.rnd_seed = 1\n",
    "c.log_interval = 200\n",
    "\n",
    "c.train_loader = {\n",
    "    torch.utils.data.DataLoader: {\n",
    "        'dataset': {\n",
    "            datasets.MNIST: {\n",
    "                'root': 'experiment_dir/data/',\n",
    "                'train': True,\n",
    "                'download': True,\n",
    "                'transform': {\n",
    "                    transforms.ToTensor: {}\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        'batch_size': c.batch_size,\n",
    "        **c.data_loader_kwargs\n",
    "    }\n",
    "}\n",
    "\n",
    "c.test_loader = {\n",
    "    torch.utils.data.DataLoader: {\n",
    "        'dataset': {\n",
    "            datasets.MNIST: {\n",
    "                'root': 'experiment_dir/data/',\n",
    "                'train': False,\n",
    "                'download': True,\n",
    "                'transform': {\n",
    "                    transforms.ToTensor: {}\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        'batch_size': c.batch_size_test,\n",
    "        **c.data_loader_kwargs\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a simple cnn model\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST_experiment(PyTorchExperiment):\n",
    "    def setup(self):\n",
    "        self.train_data_loader = self.config.train_loader\n",
    "        self.test_data_loader = self.config.test_loader\n",
    "        self.model = Net()\n",
    "        if self.config.use_cuda:\n",
    "            self.model.cuda()\n",
    "        self.optimizer = optim.SGD(self.model.parameters(), lr=self.config.learning_rate,\n",
    "                                               momentum=self.config.momentum)\n",
    "        self.save_checkpoint(name=\"checkpoint_start\")\n",
    "        self.vlog.plot_model_structure(self.model,\n",
    "                                       [self.config.batch_size, 1, 28, 28], \n",
    "                                       name='Model Structure')\n",
    "        self.elog.print('Experiment set up.')\n",
    "        self.batch_counter = 0\n",
    "    \n",
    "    def train(self, epoch):\n",
    "        self.model.train()\n",
    "        for batch_idx, (data, target) in enumerate(self.train_data_loader):\n",
    "            self.batch_counter += 1\n",
    "            if self.config.use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            data, target = Variable(data), Variable(target)\n",
    "            self.optimizer.zero_grad()\n",
    "            output = self.model(data)\n",
    "            self.loss = F.nll_loss(output, target)\n",
    "            self.loss.backward()\n",
    "            self.optimizer.step()\n",
    "            if batch_idx % self.config.log_interval == 0:\n",
    "                # plot train loss\n",
    "                self.vlog.show_value(value=self.loss.data[0], name='Loss',\n",
    "                                     count=self.batch_counter, tag='Train Loss')\n",
    "                # log train batch loss and progress\n",
    "                self.elog.print(\n",
    "                    'Train Epoch: {} [{}/{} samples ({:.0f}%)]\\t Batch Loss: {:.6f}'\n",
    "                    .format(epoch, batch_idx * len(data),\n",
    "                            len(self.train_data_loader.dataset),\n",
    "                            100. * batch_idx / len(self.train_data_loader),\n",
    "                            self.loss.data[0]))\n",
    "                self.save_checkpoint(name=\"checkpoint\", n_iter=batch_idx)\n",
    "                \n",
    "    def validate(self, epoch):\n",
    "        self.model.eval()\n",
    "        validation_loss = 0\n",
    "        correct = 0\n",
    "        for data, target in self.test_data_loader:\n",
    "            if self.config.use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            data, target = Variable(data, volatile=True), Variable(target)\n",
    "            output = self.model(data)\n",
    "            validation_loss += F.nll_loss(output, target, size_average=False).data[0]\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "        validation_loss /= len(self.test_data_loader.dataset)\n",
    "        # plot the test loss\n",
    "        self.vlog.show_value(value=validation_loss, name='Loss',\n",
    "                             count=self.batch_counter, tag='Validation Loss')\n",
    "        # log validation loss and accuracy\n",
    "        self.elog.print(\n",
    "            '\\nValidation set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'\n",
    "            .format(validation_loss, correct, len(self.test_data_loader.dataset),\n",
    "                    100. * correct / len(self.test_data_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = MNIST_experiment(config=c, name='experiment', n_epochs=c.n_epochs, \n",
    "                       seed=42, base_dir='./experiment_dir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment set up.\n",
      "Train Epoch: 0 [0/60000 samples (0%)]\t Batch Loss: 2.316128\n",
      "Train Epoch: 0 [12800/60000 samples (21%)]\t Batch Loss: 0.820707\n",
      "Train Epoch: 0 [25600/60000 samples (43%)]\t Batch Loss: 0.534265\n",
      "Train Epoch: 0 [38400/60000 samples (64%)]\t Batch Loss: 0.366489\n",
      "Train Epoch: 0 [51200/60000 samples (85%)]\t Batch Loss: 0.550541\n",
      "\n",
      "Validation set: Average loss: 0.1432, Accuracy: 9575/10000 (96%)\n",
      "\n",
      "Train Epoch: 1 [0/60000 samples (0%)]\t Batch Loss: 0.385810\n",
      "Train Epoch: 1 [12800/60000 samples (21%)]\t Batch Loss: 0.192033\n",
      "Train Epoch: 1 [25600/60000 samples (43%)]\t Batch Loss: 0.267174\n",
      "Train Epoch: 1 [38400/60000 samples (64%)]\t Batch Loss: 0.294016\n",
      "Train Epoch: 1 [51200/60000 samples (85%)]\t Batch Loss: 0.324068\n",
      "\n",
      "Validation set: Average loss: 0.0937, Accuracy: 9706/10000 (97%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 samples (0%)]\t Batch Loss: 0.138147\n",
      "Train Epoch: 2 [12800/60000 samples (21%)]\t Batch Loss: 0.257049\n",
      "Train Epoch: 2 [25600/60000 samples (43%)]\t Batch Loss: 0.284057\n",
      "Train Epoch: 2 [38400/60000 samples (64%)]\t Batch Loss: 0.239447\n",
      "Train Epoch: 2 [51200/60000 samples (85%)]\t Batch Loss: 0.247796\n",
      "\n",
      "Validation set: Average loss: 0.0740, Accuracy: 9768/10000 (98%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 samples (0%)]\t Batch Loss: 0.167097\n",
      "Train Epoch: 3 [12800/60000 samples (21%)]\t Batch Loss: 0.170049\n",
      "Train Epoch: 3 [25600/60000 samples (43%)]\t Batch Loss: 0.274751\n",
      "Train Epoch: 3 [38400/60000 samples (64%)]\t Batch Loss: 0.227394\n",
      "Train Epoch: 3 [51200/60000 samples (85%)]\t Batch Loss: 0.247839\n",
      "\n",
      "Validation set: Average loss: 0.0658, Accuracy: 9803/10000 (98%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 samples (0%)]\t Batch Loss: 0.128103\n",
      "Train Epoch: 4 [12800/60000 samples (21%)]\t Batch Loss: 0.214746\n",
      "Train Epoch: 4 [25600/60000 samples (43%)]\t Batch Loss: 0.214768\n",
      "Train Epoch: 4 [38400/60000 samples (64%)]\t Batch Loss: 0.182726\n",
      "Train Epoch: 4 [51200/60000 samples (85%)]\t Batch Loss: 0.250992\n",
      "\n",
      "Validation set: Average loss: 0.0609, Accuracy: 9809/10000 (98%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 samples (0%)]\t Batch Loss: 0.093310\n",
      "Train Epoch: 5 [12800/60000 samples (21%)]\t Batch Loss: 0.283067\n",
      "Train Epoch: 5 [25600/60000 samples (43%)]\t Batch Loss: 0.050560\n",
      "Train Epoch: 5 [38400/60000 samples (64%)]\t Batch Loss: 0.089850\n",
      "Train Epoch: 5 [51200/60000 samples (85%)]\t Batch Loss: 0.450200\n",
      "\n",
      "Validation set: Average loss: 0.0545, Accuracy: 9825/10000 (98%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 samples (0%)]\t Batch Loss: 0.155736\n",
      "Train Epoch: 6 [12800/60000 samples (21%)]\t Batch Loss: 0.130226\n",
      "Train Epoch: 6 [25600/60000 samples (43%)]\t Batch Loss: 0.157364\n",
      "Train Epoch: 6 [38400/60000 samples (64%)]\t Batch Loss: 0.195920\n",
      "Train Epoch: 6 [51200/60000 samples (85%)]\t Batch Loss: 0.393081\n",
      "\n",
      "Validation set: Average loss: 0.0539, Accuracy: 9832/10000 (98%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 samples (0%)]\t Batch Loss: 0.156292\n",
      "Train Epoch: 7 [12800/60000 samples (21%)]\t Batch Loss: 0.151154\n",
      "Train Epoch: 7 [25600/60000 samples (43%)]\t Batch Loss: 0.135682\n",
      "Train Epoch: 7 [38400/60000 samples (64%)]\t Batch Loss: 0.163983\n",
      "Train Epoch: 7 [51200/60000 samples (85%)]\t Batch Loss: 0.409413\n",
      "\n",
      "Validation set: Average loss: 0.0522, Accuracy: 9821/10000 (98%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 samples (0%)]\t Batch Loss: 0.108265\n",
      "Train Epoch: 8 [12800/60000 samples (21%)]\t Batch Loss: 0.162425\n",
      "Train Epoch: 8 [25600/60000 samples (43%)]\t Batch Loss: 0.044691\n",
      "Train Epoch: 8 [38400/60000 samples (64%)]\t Batch Loss: 0.098933\n",
      "Train Epoch: 8 [51200/60000 samples (85%)]\t Batch Loss: 0.365530\n",
      "\n",
      "Validation set: Average loss: 0.0454, Accuracy: 9860/10000 (99%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 samples (0%)]\t Batch Loss: 0.092713\n",
      "Train Epoch: 9 [12800/60000 samples (21%)]\t Batch Loss: 0.198614\n",
      "Train Epoch: 9 [25600/60000 samples (43%)]\t Batch Loss: 0.058338\n",
      "Train Epoch: 9 [38400/60000 samples (64%)]\t Batch Loss: 0.112591\n",
      "Train Epoch: 9 [51200/60000 samples (85%)]\t Batch Loss: 0.335576\n",
      "\n",
      "Validation set: Average loss: 0.0432, Accuracy: 9867/10000 (99%)\n",
      "\n",
      "Trained.\n",
      "Experiment ended. Checkpoints stored =)\n"
     ]
    }
   ],
   "source": [
    "exp.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "last_experiment = 'experiment_dir/' + sorted([d for d in os.listdir('experiment_dir/') if '20' in str(d)], reverse=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180320-153955_experiment  data  test-experiment  test-experiment2\n"
     ]
    }
   ],
   "source": [
    "!ls experiment_dir/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'experiment_dir/20180320-153955_experiment'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint_00000.pth.tar  checkpoint_00600.pth.tar    checkpoint_last.pth.tar\n",
      "checkpoint_00200.pth.tar  checkpoint_00800.pth.tar    checkpoint_start.pth.tar\n",
      "checkpoint_00400.pth.tar  checkpoint_current.pth.tar\n"
     ]
    }
   ],
   "source": [
    "!ls experiment_dir/20180320-153955_experiment/checkpoint/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vislogger.experiment import PyTorchExperiment\n",
    "exp_resume = MNIST_experiment(config=c, name='resume_experiment', \n",
    "                              n_epochs=c.n_epochs, seed=42, base_dir='./experiment_dir', \n",
    "                              resume=last_experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_resume.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls experiment_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
