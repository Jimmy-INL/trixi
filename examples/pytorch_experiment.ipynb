{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## trixi PyTorch Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from trixi import Config\n",
    "from trixi.experiment import PyTorchExperiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180322-131854_experiment  data  test-experiment  test-experiment2\n"
     ]
    }
   ],
   "source": [
    "!ls experiment_dir/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf experiment_dir/20*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107M\texperiment_dir/\n"
     ]
    }
   ],
   "source": [
    "!du -sh experiment_dir/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Config()\n",
    "\n",
    "c.batch_size = 64\n",
    "c.batch_size_test = 1000\n",
    "c.n_epochs = 10\n",
    "c.learning_rate = 0.01\n",
    "c.momentum = 0.9\n",
    "if torch.cuda.is_available():\n",
    "    c.use_cuda = True\n",
    "else:\n",
    "    c.use_cuda = False\n",
    "c.data_loader_kwargs = {'num_workers': 1, 'pin_memory': True} if c.use_cuda else {}\n",
    "c.rnd_seed = 1\n",
    "c.log_interval = 200\n",
    "\n",
    "c.train_loader = {\n",
    "    torch.utils.data.DataLoader: {\n",
    "        'dataset': {\n",
    "            datasets.MNIST: {\n",
    "                'root': 'experiment_dir/data/',\n",
    "                'train': True,\n",
    "                'download': True,\n",
    "                'transform': {\n",
    "                    transforms.ToTensor: {}\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        'batch_size': c.batch_size,\n",
    "        **c.data_loader_kwargs\n",
    "    }\n",
    "}\n",
    "\n",
    "c.test_loader = {\n",
    "    torch.utils.data.DataLoader: {\n",
    "        'dataset': {\n",
    "            datasets.MNIST: {\n",
    "                'root': 'experiment_dir/data/',\n",
    "                'train': False,\n",
    "                'download': True,\n",
    "                'transform': {\n",
    "                    transforms.ToTensor: {}\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        'batch_size': c.batch_size_test,\n",
    "        **c.data_loader_kwargs\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a simple cnn model\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST_experiment(PyTorchExperiment):\n",
    "    def setup(self):\n",
    "        self.train_data_loader = self.config.train_loader\n",
    "        self.test_data_loader = self.config.test_loader\n",
    "        self.model = Net()\n",
    "        if self.config.use_cuda:\n",
    "            self.model.cuda()\n",
    "        self.optimizer = optim.SGD(self.model.parameters(), lr=self.config.learning_rate,\n",
    "                                               momentum=self.config.momentum)\n",
    "        self.save_checkpoint(name=\"checkpoint_start\")\n",
    "        self.vlog.plot_model_structure(self.model,\n",
    "                                       [self.config.batch_size, 1, 28, 28], \n",
    "                                       name='Model Structure')\n",
    "        self.elog.print('Experiment set up.')\n",
    "        self.batch_counter = 0\n",
    "    \n",
    "    def train(self, epoch):\n",
    "        self.model.train()\n",
    "        for batch_idx, (data, target) in enumerate(self.train_data_loader):\n",
    "            self.batch_counter += 1\n",
    "            if self.config.use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            data, target = Variable(data), Variable(target)\n",
    "            self.optimizer.zero_grad()\n",
    "            output = self.model(data)\n",
    "            self.loss = F.nll_loss(output, target)\n",
    "            self.loss.backward()\n",
    "            self.optimizer.step()\n",
    "            if batch_idx % self.config.log_interval == 0:\n",
    "                # plot train loss\n",
    "                self.vlog.show_value(value=self.loss.data[0], name='Loss',\n",
    "                                     count=self.batch_counter, tag='Train Loss')\n",
    "                # log train batch loss and progress\n",
    "                self.elog.print(\n",
    "                    'Train Epoch: {} [{}/{} samples ({:.0f}%)]\\t Batch Loss: {:.6f}'\n",
    "                    .format(epoch, batch_idx * len(data),\n",
    "                            len(self.train_data_loader.dataset),\n",
    "                            100. * batch_idx / len(self.train_data_loader),\n",
    "                            self.loss.data[0]))\n",
    "                self.save_checkpoint(name=\"checkpoint\", n_iter=batch_idx)\n",
    "                \n",
    "    def validate(self, epoch):\n",
    "        self.model.eval()\n",
    "        validation_loss = 0\n",
    "        correct = 0\n",
    "        for data, target in self.test_data_loader:\n",
    "            if self.config.use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            data, target = Variable(data, volatile=True), Variable(target)\n",
    "            output = self.model(data)\n",
    "            validation_loss += F.nll_loss(output, target, size_average=False).data[0]\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "        validation_loss /= len(self.test_data_loader.dataset)\n",
    "        # plot the test loss\n",
    "        self.vlog.show_value(value=validation_loss, name='Loss',\n",
    "                             count=self.batch_counter, tag='Validation Loss')\n",
    "        # log validation loss and accuracy\n",
    "        self.elog.print(\n",
    "            '\\nValidation set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'\n",
    "            .format(validation_loss, correct, len(self.test_data_loader.dataset),\n",
    "                    100. * correct / len(self.test_data_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = MNIST_experiment(config=c, name='experiment', n_epochs=c.n_epochs, \n",
    "                       seed=42, base_dir='./experiment_dir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment set up.\n",
      "Train Epoch: 0 [0/60000 samples (0%)]\t Batch Loss: 2.316128\n",
      "Train Epoch: 0 [12800/60000 samples (21%)]\t Batch Loss: 0.823947\n",
      "Train Epoch: 0 [25600/60000 samples (43%)]\t Batch Loss: 0.590966\n",
      "Train Epoch: 0 [38400/60000 samples (64%)]\t Batch Loss: 0.366278\n",
      "Train Epoch: 0 [51200/60000 samples (85%)]\t Batch Loss: 0.540924\n",
      "\n",
      "Validation set: Average loss: 0.1431, Accuracy: 9557/10000 (96%)\n",
      "\n",
      "Train Epoch: 1 [0/60000 samples (0%)]\t Batch Loss: 0.338453\n",
      "Train Epoch: 1 [12800/60000 samples (21%)]\t Batch Loss: 0.207718\n",
      "Train Epoch: 1 [25600/60000 samples (43%)]\t Batch Loss: 0.319579\n",
      "Train Epoch: 1 [38400/60000 samples (64%)]\t Batch Loss: 0.336838\n",
      "Train Epoch: 1 [51200/60000 samples (85%)]\t Batch Loss: 0.275827\n",
      "\n",
      "Validation set: Average loss: 0.0912, Accuracy: 9702/10000 (97%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 samples (0%)]\t Batch Loss: 0.119321\n",
      "Train Epoch: 2 [12800/60000 samples (21%)]\t Batch Loss: 0.244302\n",
      "Train Epoch: 2 [25600/60000 samples (43%)]\t Batch Loss: 0.272762\n",
      "Train Epoch: 2 [38400/60000 samples (64%)]\t Batch Loss: 0.226339\n",
      "Train Epoch: 2 [51200/60000 samples (85%)]\t Batch Loss: 0.264949\n",
      "\n",
      "Validation set: Average loss: 0.0738, Accuracy: 9764/10000 (98%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 samples (0%)]\t Batch Loss: 0.151932\n",
      "Train Epoch: 3 [12800/60000 samples (21%)]\t Batch Loss: 0.193007\n",
      "Train Epoch: 3 [25600/60000 samples (43%)]\t Batch Loss: 0.305545\n",
      "Train Epoch: 3 [38400/60000 samples (64%)]\t Batch Loss: 0.188181\n",
      "Train Epoch: 3 [51200/60000 samples (85%)]\t Batch Loss: 0.205248\n",
      "\n",
      "Validation set: Average loss: 0.0674, Accuracy: 9800/10000 (98%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 samples (0%)]\t Batch Loss: 0.126170\n",
      "Train Epoch: 4 [12800/60000 samples (21%)]\t Batch Loss: 0.222152\n",
      "Train Epoch: 4 [25600/60000 samples (43%)]\t Batch Loss: 0.292754\n",
      "Train Epoch: 4 [38400/60000 samples (64%)]\t Batch Loss: 0.196974\n",
      "Train Epoch: 4 [51200/60000 samples (85%)]\t Batch Loss: 0.253340\n",
      "\n",
      "Validation set: Average loss: 0.0579, Accuracy: 9820/10000 (98%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 samples (0%)]\t Batch Loss: 0.131139\n",
      "Train Epoch: 5 [12800/60000 samples (21%)]\t Batch Loss: 0.306446\n",
      "Train Epoch: 5 [25600/60000 samples (43%)]\t Batch Loss: 0.078157\n",
      "Train Epoch: 5 [38400/60000 samples (64%)]\t Batch Loss: 0.107049\n",
      "Train Epoch: 5 [51200/60000 samples (85%)]\t Batch Loss: 0.410728\n",
      "\n",
      "Validation set: Average loss: 0.0554, Accuracy: 9827/10000 (98%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 samples (0%)]\t Batch Loss: 0.138956\n",
      "Train Epoch: 6 [12800/60000 samples (21%)]\t Batch Loss: 0.106029\n",
      "Train Epoch: 6 [25600/60000 samples (43%)]\t Batch Loss: 0.127260\n",
      "Train Epoch: 6 [38400/60000 samples (64%)]\t Batch Loss: 0.182032\n",
      "Train Epoch: 6 [51200/60000 samples (85%)]\t Batch Loss: 0.535374\n",
      "\n",
      "Validation set: Average loss: 0.0514, Accuracy: 9835/10000 (98%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 samples (0%)]\t Batch Loss: 0.207328\n",
      "Train Epoch: 7 [12800/60000 samples (21%)]\t Batch Loss: 0.146018\n",
      "Train Epoch: 7 [25600/60000 samples (43%)]\t Batch Loss: 0.147764\n",
      "Train Epoch: 7 [38400/60000 samples (64%)]\t Batch Loss: 0.144177\n",
      "Train Epoch: 7 [51200/60000 samples (85%)]\t Batch Loss: 0.295291\n",
      "\n",
      "Validation set: Average loss: 0.0490, Accuracy: 9840/10000 (98%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 samples (0%)]\t Batch Loss: 0.117410\n",
      "Train Epoch: 8 [12800/60000 samples (21%)]\t Batch Loss: 0.205859\n",
      "Train Epoch: 8 [25600/60000 samples (43%)]\t Batch Loss: 0.080982\n",
      "Train Epoch: 8 [38400/60000 samples (64%)]\t Batch Loss: 0.147698\n",
      "Train Epoch: 8 [51200/60000 samples (85%)]\t Batch Loss: 0.412475\n",
      "\n",
      "Validation set: Average loss: 0.0459, Accuracy: 9854/10000 (99%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 samples (0%)]\t Batch Loss: 0.132123\n",
      "Train Epoch: 9 [12800/60000 samples (21%)]\t Batch Loss: 0.178883\n",
      "Train Epoch: 9 [25600/60000 samples (43%)]\t Batch Loss: 0.067118\n",
      "Train Epoch: 9 [38400/60000 samples (64%)]\t Batch Loss: 0.081612\n",
      "Train Epoch: 9 [51200/60000 samples (85%)]\t Batch Loss: 0.166369\n",
      "\n",
      "Validation set: Average loss: 0.0448, Accuracy: 9861/10000 (99%)\n",
      "\n",
      "Trained.\n",
      "Experiment ended. Checkpoints stored =)\n"
     ]
    }
   ],
   "source": [
    "exp.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "last_experiment = 'experiment_dir/' + sorted([d for d in os.listdir('experiment_dir/') if '20' in str(d)], reverse=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180327-150613_experiment  data  test-experiment  test-experiment2\n"
     ]
    }
   ],
   "source": [
    "!ls experiment_dir/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'experiment_dir/20180327-150613_experiment'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint_00000.pth.tar  checkpoint_00600.pth.tar    checkpoint_last.pth.tar\n",
      "checkpoint_00200.pth.tar  checkpoint_00800.pth.tar    checkpoint_start.pth.tar\n",
      "checkpoint_00400.pth.tar  checkpoint_current.pth.tar\n"
     ]
    }
   ],
   "source": [
    "!ls experiment_dir/20180320-153955_experiment/checkpoint/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trixi.experiment import PyTorchExperiment\n",
    "exp_resume = MNIST_experiment(config=c, name='resume_experiment', \n",
    "                              n_epochs=c.n_epochs, seed=42, base_dir='./experiment_dir', \n",
    "                              resume=last_experiment, resume_save_types=('model',\n",
    "                                                                         'simple',\n",
    "                                                                         'th_vars',\n",
    "                                                                         'results'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment set up.\n",
      "Experiment set up.\n",
      "Loaded existing config from: experiment_dir/20180327-150613_experiment\n",
      "Loaded existing config from: experiment_dir/20180327-150613_experiment\n",
      "Loaded existing checkpoint from: experiment_dir/20180327-150613_experiment/checkpoint/checkpoint_last.pth.tar\n",
      "Loaded existing checkpoint from: experiment_dir/20180327-150613_experiment/checkpoint/checkpoint_last.pth.tar\n",
      "Train Epoch: 0 [0/60000 samples (0%)]\t Batch Loss: 0.075133\n",
      "Train Epoch: 0 [0/60000 samples (0%)]\t Batch Loss: 0.075133\n",
      "Train Epoch: 0 [12800/60000 samples (21%)]\t Batch Loss: 0.067080\n",
      "Train Epoch: 0 [12800/60000 samples (21%)]\t Batch Loss: 0.067080\n",
      "Train Epoch: 0 [25600/60000 samples (43%)]\t Batch Loss: 0.085577\n",
      "Train Epoch: 0 [25600/60000 samples (43%)]\t Batch Loss: 0.085577\n",
      "Train Epoch: 0 [38400/60000 samples (64%)]\t Batch Loss: 0.102218\n",
      "Train Epoch: 0 [38400/60000 samples (64%)]\t Batch Loss: 0.102218\n",
      "Train Epoch: 0 [51200/60000 samples (85%)]\t Batch Loss: 0.444704\n",
      "Train Epoch: 0 [51200/60000 samples (85%)]\t Batch Loss: 0.444704\n",
      "\n",
      "Validation set: Average loss: 0.0442, Accuracy: 9866/10000 (99%)\n",
      "\n",
      "\n",
      "Validation set: Average loss: 0.0442, Accuracy: 9866/10000 (99%)\n",
      "\n",
      "Train Epoch: 1 [0/60000 samples (0%)]\t Batch Loss: 0.064316\n",
      "Train Epoch: 1 [0/60000 samples (0%)]\t Batch Loss: 0.064316\n",
      "Train Epoch: 1 [12800/60000 samples (21%)]\t Batch Loss: 0.048227\n",
      "Train Epoch: 1 [12800/60000 samples (21%)]\t Batch Loss: 0.048227\n",
      "Train Epoch: 1 [25600/60000 samples (43%)]\t Batch Loss: 0.106201\n",
      "Train Epoch: 1 [25600/60000 samples (43%)]\t Batch Loss: 0.106201\n",
      "Train Epoch: 1 [38400/60000 samples (64%)]\t Batch Loss: 0.131224\n",
      "Train Epoch: 1 [38400/60000 samples (64%)]\t Batch Loss: 0.131224\n",
      "Train Epoch: 1 [51200/60000 samples (85%)]\t Batch Loss: 0.214662\n",
      "Train Epoch: 1 [51200/60000 samples (85%)]\t Batch Loss: 0.214662\n",
      "\n",
      "Validation set: Average loss: 0.0414, Accuracy: 9880/10000 (99%)\n",
      "\n",
      "\n",
      "Validation set: Average loss: 0.0414, Accuracy: 9880/10000 (99%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 samples (0%)]\t Batch Loss: 0.030872\n",
      "Train Epoch: 2 [0/60000 samples (0%)]\t Batch Loss: 0.030872\n",
      "Train Epoch: 2 [12800/60000 samples (21%)]\t Batch Loss: 0.241978\n",
      "Train Epoch: 2 [12800/60000 samples (21%)]\t Batch Loss: 0.241978\n",
      "Train Epoch: 2 [25600/60000 samples (43%)]\t Batch Loss: 0.075840\n",
      "Train Epoch: 2 [25600/60000 samples (43%)]\t Batch Loss: 0.075840\n",
      "Train Epoch: 2 [38400/60000 samples (64%)]\t Batch Loss: 0.092093\n",
      "Train Epoch: 2 [38400/60000 samples (64%)]\t Batch Loss: 0.092093\n",
      "Train Epoch: 2 [51200/60000 samples (85%)]\t Batch Loss: 0.136488\n",
      "Train Epoch: 2 [51200/60000 samples (85%)]\t Batch Loss: 0.136488\n",
      "\n",
      "Validation set: Average loss: 0.0407, Accuracy: 9875/10000 (99%)\n",
      "\n",
      "\n",
      "Validation set: Average loss: 0.0407, Accuracy: 9875/10000 (99%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 samples (0%)]\t Batch Loss: 0.124835\n",
      "Train Epoch: 3 [0/60000 samples (0%)]\t Batch Loss: 0.124835\n",
      "Train Epoch: 3 [12800/60000 samples (21%)]\t Batch Loss: 0.177271\n",
      "Train Epoch: 3 [12800/60000 samples (21%)]\t Batch Loss: 0.177271\n",
      "Train Epoch: 3 [25600/60000 samples (43%)]\t Batch Loss: 0.117623\n",
      "Train Epoch: 3 [25600/60000 samples (43%)]\t Batch Loss: 0.117623\n",
      "Train Epoch: 3 [38400/60000 samples (64%)]\t Batch Loss: 0.110341\n",
      "Train Epoch: 3 [38400/60000 samples (64%)]\t Batch Loss: 0.110341\n",
      "Train Epoch: 3 [51200/60000 samples (85%)]\t Batch Loss: 0.135202\n",
      "Train Epoch: 3 [51200/60000 samples (85%)]\t Batch Loss: 0.135202\n",
      "\n",
      "Validation set: Average loss: 0.0397, Accuracy: 9881/10000 (99%)\n",
      "\n",
      "\n",
      "Validation set: Average loss: 0.0397, Accuracy: 9881/10000 (99%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 samples (0%)]\t Batch Loss: 0.139861\n",
      "Train Epoch: 4 [0/60000 samples (0%)]\t Batch Loss: 0.139861\n",
      "Train Epoch: 4 [12800/60000 samples (21%)]\t Batch Loss: 0.190763\n",
      "Train Epoch: 4 [12800/60000 samples (21%)]\t Batch Loss: 0.190763\n",
      "Train Epoch: 4 [25600/60000 samples (43%)]\t Batch Loss: 0.320011\n",
      "Train Epoch: 4 [25600/60000 samples (43%)]\t Batch Loss: 0.320011\n",
      "Train Epoch: 4 [38400/60000 samples (64%)]\t Batch Loss: 0.137912\n",
      "Train Epoch: 4 [38400/60000 samples (64%)]\t Batch Loss: 0.137912\n",
      "Train Epoch: 4 [51200/60000 samples (85%)]\t Batch Loss: 0.269541\n",
      "Train Epoch: 4 [51200/60000 samples (85%)]\t Batch Loss: 0.269541\n",
      "\n",
      "Validation set: Average loss: 0.0412, Accuracy: 9881/10000 (99%)\n",
      "\n",
      "\n",
      "Validation set: Average loss: 0.0412, Accuracy: 9881/10000 (99%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 samples (0%)]\t Batch Loss: 0.064347\n",
      "Train Epoch: 5 [0/60000 samples (0%)]\t Batch Loss: 0.064347\n",
      "Train Epoch: 5 [12800/60000 samples (21%)]\t Batch Loss: 0.130216\n",
      "Train Epoch: 5 [12800/60000 samples (21%)]\t Batch Loss: 0.130216\n",
      "Train Epoch: 5 [25600/60000 samples (43%)]\t Batch Loss: 0.047891\n",
      "Train Epoch: 5 [25600/60000 samples (43%)]\t Batch Loss: 0.047891\n",
      "Train Epoch: 5 [38400/60000 samples (64%)]\t Batch Loss: 0.057562\n",
      "Train Epoch: 5 [38400/60000 samples (64%)]\t Batch Loss: 0.057562\n",
      "Train Epoch: 5 [51200/60000 samples (85%)]\t Batch Loss: 0.324573\n",
      "Train Epoch: 5 [51200/60000 samples (85%)]\t Batch Loss: 0.324573\n",
      "\n",
      "Validation set: Average loss: 0.0369, Accuracy: 9891/10000 (99%)\n",
      "\n",
      "\n",
      "Validation set: Average loss: 0.0369, Accuracy: 9891/10000 (99%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 samples (0%)]\t Batch Loss: 0.074600\n",
      "Train Epoch: 6 [0/60000 samples (0%)]\t Batch Loss: 0.074600\n",
      "Train Epoch: 6 [12800/60000 samples (21%)]\t Batch Loss: 0.187842\n",
      "Train Epoch: 6 [12800/60000 samples (21%)]\t Batch Loss: 0.187842\n",
      "Train Epoch: 6 [25600/60000 samples (43%)]\t Batch Loss: 0.053237\n",
      "Train Epoch: 6 [25600/60000 samples (43%)]\t Batch Loss: 0.053237\n",
      "Train Epoch: 6 [38400/60000 samples (64%)]\t Batch Loss: 0.119028\n",
      "Train Epoch: 6 [38400/60000 samples (64%)]\t Batch Loss: 0.119028\n",
      "Train Epoch: 6 [51200/60000 samples (85%)]\t Batch Loss: 0.500448\n",
      "Train Epoch: 6 [51200/60000 samples (85%)]\t Batch Loss: 0.500448\n",
      "\n",
      "Validation set: Average loss: 0.0379, Accuracy: 9878/10000 (99%)\n",
      "\n",
      "\n",
      "Validation set: Average loss: 0.0379, Accuracy: 9878/10000 (99%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 samples (0%)]\t Batch Loss: 0.124963\n",
      "Train Epoch: 7 [0/60000 samples (0%)]\t Batch Loss: 0.124963\n",
      "Train Epoch: 7 [12800/60000 samples (21%)]\t Batch Loss: 0.138955\n",
      "Train Epoch: 7 [12800/60000 samples (21%)]\t Batch Loss: 0.138955\n",
      "Train Epoch: 7 [25600/60000 samples (43%)]\t Batch Loss: 0.075620\n",
      "Train Epoch: 7 [25600/60000 samples (43%)]\t Batch Loss: 0.075620\n",
      "Train Epoch: 7 [38400/60000 samples (64%)]\t Batch Loss: 0.110318\n",
      "Train Epoch: 7 [38400/60000 samples (64%)]\t Batch Loss: 0.110318\n",
      "Train Epoch: 7 [51200/60000 samples (85%)]\t Batch Loss: 0.248947\n",
      "Train Epoch: 7 [51200/60000 samples (85%)]\t Batch Loss: 0.248947\n",
      "\n",
      "Validation set: Average loss: 0.0384, Accuracy: 9881/10000 (99%)\n",
      "\n",
      "\n",
      "Validation set: Average loss: 0.0384, Accuracy: 9881/10000 (99%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 samples (0%)]\t Batch Loss: 0.082836\n",
      "Train Epoch: 8 [0/60000 samples (0%)]\t Batch Loss: 0.082836\n",
      "Train Epoch: 8 [12800/60000 samples (21%)]\t Batch Loss: 0.193708\n",
      "Train Epoch: 8 [12800/60000 samples (21%)]\t Batch Loss: 0.193708\n",
      "Train Epoch: 8 [25600/60000 samples (43%)]\t Batch Loss: 0.046448\n",
      "Train Epoch: 8 [25600/60000 samples (43%)]\t Batch Loss: 0.046448\n",
      "Train Epoch: 8 [38400/60000 samples (64%)]\t Batch Loss: 0.076015\n",
      "Train Epoch: 8 [38400/60000 samples (64%)]\t Batch Loss: 0.076015\n",
      "Train Epoch: 8 [51200/60000 samples (85%)]\t Batch Loss: 0.302479\n",
      "Train Epoch: 8 [51200/60000 samples (85%)]\t Batch Loss: 0.302479\n",
      "\n",
      "Validation set: Average loss: 0.0379, Accuracy: 9871/10000 (99%)\n",
      "\n",
      "\n",
      "Validation set: Average loss: 0.0379, Accuracy: 9871/10000 (99%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 samples (0%)]\t Batch Loss: 0.061577\n",
      "Train Epoch: 9 [0/60000 samples (0%)]\t Batch Loss: 0.061577\n",
      "Train Epoch: 9 [12800/60000 samples (21%)]\t Batch Loss: 0.174409\n",
      "Train Epoch: 9 [12800/60000 samples (21%)]\t Batch Loss: 0.174409\n",
      "Train Epoch: 9 [25600/60000 samples (43%)]\t Batch Loss: 0.053366\n",
      "Train Epoch: 9 [25600/60000 samples (43%)]\t Batch Loss: 0.053366\n",
      "Train Epoch: 9 [38400/60000 samples (64%)]\t Batch Loss: 0.066179\n",
      "Train Epoch: 9 [38400/60000 samples (64%)]\t Batch Loss: 0.066179\n",
      "Train Epoch: 9 [51200/60000 samples (85%)]\t Batch Loss: 0.118135\n",
      "Train Epoch: 9 [51200/60000 samples (85%)]\t Batch Loss: 0.118135\n",
      "\n",
      "Validation set: Average loss: 0.0372, Accuracy: 9899/10000 (99%)\n",
      "\n",
      "\n",
      "Validation set: Average loss: 0.0372, Accuracy: 9899/10000 (99%)\n",
      "\n",
      "Trained.\n",
      "Experiment ended. Checkpoints stored =)\n",
      "Experiment ended. Checkpoints stored =)\n"
     ]
    }
   ],
   "source": [
    "exp_resume.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180327-150613_experiment\t   data\n",
      "20180327-152845_resume_experiment  test-experiment\n",
      "20180327-153258_resume_experiment  test-experiment2\n"
     ]
    }
   ],
   "source": [
    "!ls experiment_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
