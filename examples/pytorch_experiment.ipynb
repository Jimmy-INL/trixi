{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A trixi PyTorch Experiment (MNIST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows how to use the trixi `PytorchExperiment` with the Pytorch MNIST example to classify mnist digits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running call:  \n",
    "`python -m visdom.server -p 8080`  \n",
    "This starts a visdom server which is used to visualize the training's progress in real-time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:This caffe2 python run does not have GPU support. Will run in CPU only mode.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from trixi.util import Config\n",
    "from trixi.experiment import PytorchExperiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's prepare the experiment dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: experiment_dir/: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir experiment_dir/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mdata\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "!ls experiment_dir/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf experiment_dir/20*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105M\texperiment_dir/\n"
     ]
    }
   ],
   "source": [
    "!du -sh experiment_dir/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create a Config. \n",
    "A config is basically a dict (which can be accessed with the \".\" operator).\n",
    "All objects in the dict will be initialized when the experiment starts.\n",
    "Additonally all config keywords/elements can be parsed over the command line (e.g. --batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Config()\n",
    "\n",
    "c.batch_size = 64\n",
    "c.batch_size_test = 1000\n",
    "c.n_epochs = 10\n",
    "c.learning_rate = 0.01\n",
    "c.momentum = 0.9\n",
    "if torch.cuda.is_available():\n",
    "    c.use_cuda = True\n",
    "else:\n",
    "    c.use_cuda = False\n",
    "c.rnd_seed = 1\n",
    "c.log_interval = 200\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define the Model we use for classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a simple cnn model\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now setup a PytorchExperiment. For this we create a class which inherits the PytorchExperiment class.  \n",
    "We then overwrite the setup, train and validate method (if we have an experiment with a standard training loop). \n",
    "When we finally call the experiement.run() method it will call the setup, and then for the defined number of n_epochs it will call the train and validate method in an alternating fashion.\n",
    "\n",
    "The PytorchExperiment has serveral benefits:\n",
    "* It automatically creates a experimentLogger (elog) which will create a pre-defined folder structure and can be used to store all the results.\n",
    "* We can specify additional loggers by initializing the PytorchExperiment with a dict mapping our desired logger name to the logger's settings.\n",
    "    * For example, if we want to use the visdom logger, we can use `loggers = {'visdom': 'visdom'}` we use a visdom logger which can be accessed via `exp.loggers['visdom']` later on.  \n",
    "    Note again that for the visdom logger to work, we have to have a visdom server running.\n",
    "* The PytorchExperiment also automatically creates a combinedLogger (clog) which has the same interface as the experimentLogger and visdomLogger and logs to both in defined interval (e.g. you can see each result in visdom, while only saving every 10th on your hard disk). If you want to use a different frequency than the default of 10, you have to specify this when initializing the experiment with the logger dict, e.g. `loggers = {'vlog': ['visdom', 5]}` if you want to use a frequency of 5.\n",
    "* After each epoch and at the end, if an error occours, it automatically stores a checkpoint of your experiment\n",
    "* You can simply resume an ended experiment by provinding its experiment folder when creating a new one\n",
    "* You can use the add_result method to compare your experiments in the trixi browser, backtrace all your result updates, and see all the results on your visdom server (at the same time)\n",
    "* Save your config and your code (if given globs=globals()) for full reproducibility)\n",
    "* Many more ;-)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST_experiment(PytorchExperiment):\n",
    "    def setup(self):\n",
    "        \n",
    "        self.elog.print(\"Config:\")\n",
    "        self.elog.print(self.config)\n",
    "        \n",
    "        ### Get Dataset\n",
    "        transf = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])\n",
    "        self.dataset_train = datasets.MNIST(root=\"experiment_dir/data/\", download=True,\n",
    "                                                        transform=transf, train=True)\n",
    "        self.dataset_test = datasets.MNIST(root=\"experiment_dir/data/\", download=True,\n",
    "                                                       transform=transf, train=False)\n",
    "\n",
    "        data_loader_kwargs = {'num_workers': 1, 'pin_memory': True} if self.config.use_cuda else {}\n",
    "        \n",
    "        self.train_data_loader = torch.utils.data.DataLoader(self.dataset_train, batch_size=self.config.batch_size,\n",
    "                                                        shuffle=True, **data_loader_kwargs)\n",
    "        self.test_data_loader = torch.utils.data.DataLoader(self.dataset_test, batch_size=self.config.batch_size,\n",
    "                                                       shuffle=True, **data_loader_kwargs)\n",
    "\n",
    "        \n",
    "        self.device = torch.device(\"cuda\" if self.config.use_cuda else \"cpu\")\n",
    "        \n",
    "        self.model = Net()\n",
    "        self.model.to(self.device)\n",
    "\n",
    "        self.optimizer = optim.SGD(self.model.parameters(), lr=self.config.learning_rate,\n",
    "                                               momentum=self.config.momentum)\n",
    "        \n",
    "        self.save_checkpoint(name=\"checkpoint_start\")\n",
    "        self.vlog.plot_model_structure(self.model,\n",
    "                                       [self.config.batch_size, 1, 28, 28], \n",
    "                                       name='Model Structure')\n",
    "        \n",
    "        self.batch_counter = 0        \n",
    "        self.elog.print('Experiment set up.')\n",
    "        \n",
    "    \n",
    "    def train(self, epoch):\n",
    "        \n",
    "        self.model.train()\n",
    "        \n",
    "        for batch_idx, (data, target) in enumerate(self.train_data_loader):\n",
    "            \n",
    "            self.batch_counter += 1\n",
    "            \n",
    "            if self.config.use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "                \n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "            output = self.model(data)\n",
    "            self.loss = F.nll_loss(output, target)\n",
    "            self.loss.backward()\n",
    "            \n",
    "            self.optimizer.step()\n",
    "            \n",
    "            if batch_idx % self.config.log_interval == 0:\n",
    "                # plot train loss (mathematically mot 100% correct, just so that lisa can sleep at night (if no one is breathing next to her ;-P) )\n",
    "                self.add_result(value=self.loss.item(), name='Train_Loss',\n",
    "                                     counter=epoch + batch_idx / len(self.train_data_loader), label='Loss')\n",
    "                # log train batch loss and progress\n",
    "                self.clog.show_text(\n",
    "                    'Train Epoch: {} [{}/{} samples ({:.0f}%)]\\t Batch Loss: {:.6f}'\n",
    "                    .format(epoch, batch_idx * len(data),\n",
    "                            len(self.train_data_loader.dataset),\n",
    "                            100. * batch_idx / len(self.train_data_loader),\n",
    "                            self.loss.item()), name=\"log\")\n",
    "                \n",
    "                self.clog.show_image_grid(data, name=\"mnist_training\", n_iter=epoch + batch_idx / len(self.train_data_loader), iter_format=\"{:0.02f}\")\n",
    "                \n",
    "                self.save_checkpoint(name=\"checkpoint\", n_iter=batch_idx)\n",
    "                \n",
    "    def validate(self, epoch):\n",
    "        self.model.eval()\n",
    "        \n",
    "        validation_loss = 0\n",
    "        correct = 0\n",
    "        \n",
    "        for data, target in self.test_data_loader:\n",
    "            if self.config.use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            output = self.model(data)\n",
    "            validation_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).cpu().sum().item()\n",
    "        validation_loss /= len(self.test_data_loader.dataset)\n",
    "        # plot the test loss\n",
    "        self.add_result(value=validation_loss, name='Validation_Loss',\n",
    "                             counter=epoch + 1, label='Loss')\n",
    "        # plot the test accuracy\n",
    "        acc = 100. * correct / len(self.test_data_loader.dataset)\n",
    "        self.add_result(value=acc, name='ValidationAccurracy',\n",
    "                             counter=epoch + 1, label='Accurracy' )\n",
    "        \n",
    "        # log validation loss and accuracy\n",
    "        self.elog.print(\n",
    "            '\\nValidation set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'\n",
    "            .format(validation_loss, correct, len(self.test_data_loader.dataset),\n",
    "                    100. * correct / len(self.test_data_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Setting up a new session...\n"
     ]
    }
   ],
   "source": [
    "exp = MNIST_experiment(config=c, name='experiment', n_epochs=c.n_epochs, \n",
    "                       seed=42, base_dir='./experiment_dir', loggers={\"visdom\": \"visdom\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-r7nVjR476Z:Config:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"base_dir\": \"./experiment_dir\",\n",
      "    \"batch_size\": 64,\n",
      "    \"batch_size_test\": 1000,\n",
      "    \"learning_rate\": 0.01,\n",
      "    \"log_interval\": 200,\n",
      "    \"momentum\": 0.9,\n",
      "    \"n_epochs\": 10,\n",
      "    \"name\": \"experiment\",\n",
      "    \"rnd_seed\": 1,\n",
      "    \"seed\": 42,\n",
      "    \"use_cuda\": false\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-r7nVjR476Z:{\n",
      "    \"base_dir\": \"./experiment_dir\",\n",
      "    \"batch_size\": 64,\n",
      "    \"batch_size_test\": 1000,\n",
      "    \"learning_rate\": 0.01,\n",
      "    \"log_interval\": 200,\n",
      "    \"momentum\": 0.9,\n",
      "    \"n_epochs\": 10,\n",
      "    \"name\": \"experiment\",\n",
      "    \"rnd_seed\": 1,\n",
      "    \"seed\": 42,\n",
      "    \"use_cuda\": false\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment set up.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gkoehler/Anaconda-Envs/trixi_dev/trixi/trixi/logger/visdom/pytorchvisdomlogger.py:286: UserWarning: Could not render model, make sure the Graphviz executables are on your system.\n",
      "  warnings.warn(\"Could not render model, make sure the Graphviz executables are on your system.\")\n",
      "INFO:default-r7nVjR476Z:Experiment set up.\n",
      "/Users/gkoehler/Anaconda-Envs/trixi_dev/trixi/trixi/experiment/pytorchexperiment.py:830: UserWarning: label in add_result is deprecated, please use tag instead\n",
      "  warnings.warn(\"label in add_result is deprecated, please use tag instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment started.\n",
      "log: Train Epoch: 0 [0/60000 samples (0%)]\t Batch Loss: 2.328166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-r7nVjR476Z:log: Train Epoch: 0 [0/60000 samples (0%)]\t Batch Loss: 2.328166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 0 [12800/60000 samples (21%)]\t Batch Loss: 0.969945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-r7nVjR476Z:log: Train Epoch: 0 [12800/60000 samples (21%)]\t Batch Loss: 0.969945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 0 [25600/60000 samples (43%)]\t Batch Loss: 0.568431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-r7nVjR476Z:log: Train Epoch: 0 [25600/60000 samples (43%)]\t Batch Loss: 0.568431\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 0 [38400/60000 samples (64%)]\t Batch Loss: 0.472517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-r7nVjR476Z:log: Train Epoch: 0 [38400/60000 samples (64%)]\t Batch Loss: 0.472517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 0 [51200/60000 samples (85%)]\t Batch Loss: 0.352993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-r7nVjR476Z:log: Train Epoch: 0 [51200/60000 samples (85%)]\t Batch Loss: 0.352993\n",
      "/anaconda3/envs/trixi_dev/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation set: Average loss: 0.0970, Accuracy: 9693/10000 (97%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-r7nVjR476Z:\n",
      "Validation set: Average loss: 0.0970, Accuracy: 9693/10000 (97%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 1 [0/60000 samples (0%)]\t Batch Loss: 0.246695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-r7nVjR476Z:log: Train Epoch: 1 [0/60000 samples (0%)]\t Batch Loss: 0.246695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 1 [12800/60000 samples (21%)]\t Batch Loss: 0.250249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-r7nVjR476Z:log: Train Epoch: 1 [12800/60000 samples (21%)]\t Batch Loss: 0.250249\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 1 [25600/60000 samples (43%)]\t Batch Loss: 0.156563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-r7nVjR476Z:log: Train Epoch: 1 [25600/60000 samples (43%)]\t Batch Loss: 0.156563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 1 [38400/60000 samples (64%)]\t Batch Loss: 0.183054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-r7nVjR476Z:log: Train Epoch: 1 [38400/60000 samples (64%)]\t Batch Loss: 0.183054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 1 [51200/60000 samples (85%)]\t Batch Loss: 0.432096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-r7nVjR476Z:log: Train Epoch: 1 [51200/60000 samples (85%)]\t Batch Loss: 0.432096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation set: Average loss: 0.0653, Accuracy: 9796/10000 (98%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-r7nVjR476Z:\n",
      "Validation set: Average loss: 0.0653, Accuracy: 9796/10000 (98%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 2 [0/60000 samples (0%)]\t Batch Loss: 0.549194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-r7nVjR476Z:log: Train Epoch: 2 [0/60000 samples (0%)]\t Batch Loss: 0.549194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 2 [12800/60000 samples (21%)]\t Batch Loss: 0.407885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-r7nVjR476Z:log: Train Epoch: 2 [12800/60000 samples (21%)]\t Batch Loss: 0.407885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 2 [25600/60000 samples (43%)]\t Batch Loss: 0.108530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-r7nVjR476Z:log: Train Epoch: 2 [25600/60000 samples (43%)]\t Batch Loss: 0.108530\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 2 [38400/60000 samples (64%)]\t Batch Loss: 0.181980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-r7nVjR476Z:log: Train Epoch: 2 [38400/60000 samples (64%)]\t Batch Loss: 0.181980\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 2 [51200/60000 samples (85%)]\t Batch Loss: 0.221101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-r7nVjR476Z:log: Train Epoch: 2 [51200/60000 samples (85%)]\t Batch Loss: 0.221101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation set: Average loss: 0.0591, Accuracy: 9830/10000 (98%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-r7nVjR476Z:\n",
      "Validation set: Average loss: 0.0591, Accuracy: 9830/10000 (98%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 3 [0/60000 samples (0%)]\t Batch Loss: 0.272039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-r7nVjR476Z:log: Train Epoch: 3 [0/60000 samples (0%)]\t Batch Loss: 0.272039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 3 [12800/60000 samples (21%)]\t Batch Loss: 0.192959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-r7nVjR476Z:log: Train Epoch: 3 [12800/60000 samples (21%)]\t Batch Loss: 0.192959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 3 [25600/60000 samples (43%)]\t Batch Loss: 0.364547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-r7nVjR476Z:log: Train Epoch: 3 [25600/60000 samples (43%)]\t Batch Loss: 0.364547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 3 [38400/60000 samples (64%)]\t Batch Loss: 0.109293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-r7nVjR476Z:log: Train Epoch: 3 [38400/60000 samples (64%)]\t Batch Loss: 0.109293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 3 [51200/60000 samples (85%)]\t Batch Loss: 0.081812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-r7nVjR476Z:log: Train Epoch: 3 [51200/60000 samples (85%)]\t Batch Loss: 0.081812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation set: Average loss: 0.0625, Accuracy: 9804/10000 (98%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-r7nVjR476Z:\n",
      "Validation set: Average loss: 0.0625, Accuracy: 9804/10000 (98%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 4 [0/60000 samples (0%)]\t Batch Loss: 0.257974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-r7nVjR476Z:log: Train Epoch: 4 [0/60000 samples (0%)]\t Batch Loss: 0.257974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 4 [12800/60000 samples (21%)]\t Batch Loss: 0.194746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-r7nVjR476Z:log: Train Epoch: 4 [12800/60000 samples (21%)]\t Batch Loss: 0.194746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 4 [25600/60000 samples (43%)]\t Batch Loss: 0.226701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-r7nVjR476Z:log: Train Epoch: 4 [25600/60000 samples (43%)]\t Batch Loss: 0.226701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 4 [38400/60000 samples (64%)]\t Batch Loss: 0.167773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-r7nVjR476Z:log: Train Epoch: 4 [38400/60000 samples (64%)]\t Batch Loss: 0.167773\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 4 [51200/60000 samples (85%)]\t Batch Loss: 0.044015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-r7nVjR476Z:log: Train Epoch: 4 [51200/60000 samples (85%)]\t Batch Loss: 0.044015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation set: Average loss: 0.0506, Accuracy: 9846/10000 (98%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-r7nVjR476Z:\n",
      "Validation set: Average loss: 0.0506, Accuracy: 9846/10000 (98%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 5 [0/60000 samples (0%)]\t Batch Loss: 0.277542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-r7nVjR476Z:log: Train Epoch: 5 [0/60000 samples (0%)]\t Batch Loss: 0.277542\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 5 [12800/60000 samples (21%)]\t Batch Loss: 0.115604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-r7nVjR476Z:log: Train Epoch: 5 [12800/60000 samples (21%)]\t Batch Loss: 0.115604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 5 [25600/60000 samples (43%)]\t Batch Loss: 0.142171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-r7nVjR476Z:log: Train Epoch: 5 [25600/60000 samples (43%)]\t Batch Loss: 0.142171\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 5 [38400/60000 samples (64%)]\t Batch Loss: 0.189552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-r7nVjR476Z:log: Train Epoch: 5 [38400/60000 samples (64%)]\t Batch Loss: 0.189552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 5 [51200/60000 samples (85%)]\t Batch Loss: 0.210928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-r7nVjR476Z:log: Train Epoch: 5 [51200/60000 samples (85%)]\t Batch Loss: 0.210928\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation set: Average loss: 0.0491, Accuracy: 9838/10000 (98%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-r7nVjR476Z:\n",
      "Validation set: Average loss: 0.0491, Accuracy: 9838/10000 (98%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 6 [0/60000 samples (0%)]\t Batch Loss: 0.227440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-r7nVjR476Z:log: Train Epoch: 6 [0/60000 samples (0%)]\t Batch Loss: 0.227440\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 6 [12800/60000 samples (21%)]\t Batch Loss: 0.432867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-r7nVjR476Z:log: Train Epoch: 6 [12800/60000 samples (21%)]\t Batch Loss: 0.432867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 6 [25600/60000 samples (43%)]\t Batch Loss: 0.155765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-r7nVjR476Z:log: Train Epoch: 6 [25600/60000 samples (43%)]\t Batch Loss: 0.155765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 6 [38400/60000 samples (64%)]\t Batch Loss: 0.151849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-r7nVjR476Z:log: Train Epoch: 6 [38400/60000 samples (64%)]\t Batch Loss: 0.151849\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 6 [51200/60000 samples (85%)]\t Batch Loss: 0.411159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-r7nVjR476Z:log: Train Epoch: 6 [51200/60000 samples (85%)]\t Batch Loss: 0.411159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation set: Average loss: 0.0456, Accuracy: 9849/10000 (98%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-r7nVjR476Z:\n",
      "Validation set: Average loss: 0.0456, Accuracy: 9849/10000 (98%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 7 [0/60000 samples (0%)]\t Batch Loss: 0.032793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-r7nVjR476Z:log: Train Epoch: 7 [0/60000 samples (0%)]\t Batch Loss: 0.032793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 7 [12800/60000 samples (21%)]\t Batch Loss: 0.109676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-r7nVjR476Z:log: Train Epoch: 7 [12800/60000 samples (21%)]\t Batch Loss: 0.109676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 7 [25600/60000 samples (43%)]\t Batch Loss: 0.091535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-r7nVjR476Z:log: Train Epoch: 7 [25600/60000 samples (43%)]\t Batch Loss: 0.091535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 7 [38400/60000 samples (64%)]\t Batch Loss: 0.196277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-r7nVjR476Z:log: Train Epoch: 7 [38400/60000 samples (64%)]\t Batch Loss: 0.196277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 7 [51200/60000 samples (85%)]\t Batch Loss: 0.127220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-r7nVjR476Z:log: Train Epoch: 7 [51200/60000 samples (85%)]\t Batch Loss: 0.127220\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation set: Average loss: 0.0450, Accuracy: 9869/10000 (99%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-r7nVjR476Z:\n",
      "Validation set: Average loss: 0.0450, Accuracy: 9869/10000 (99%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 8 [0/60000 samples (0%)]\t Batch Loss: 0.098203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-r7nVjR476Z:log: Train Epoch: 8 [0/60000 samples (0%)]\t Batch Loss: 0.098203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 8 [12800/60000 samples (21%)]\t Batch Loss: 0.122402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-r7nVjR476Z:log: Train Epoch: 8 [12800/60000 samples (21%)]\t Batch Loss: 0.122402\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 8 [25600/60000 samples (43%)]\t Batch Loss: 0.077075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-r7nVjR476Z:log: Train Epoch: 8 [25600/60000 samples (43%)]\t Batch Loss: 0.077075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 8 [38400/60000 samples (64%)]\t Batch Loss: 0.026567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-r7nVjR476Z:log: Train Epoch: 8 [38400/60000 samples (64%)]\t Batch Loss: 0.026567\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 8 [51200/60000 samples (85%)]\t Batch Loss: 0.064110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-r7nVjR476Z:log: Train Epoch: 8 [51200/60000 samples (85%)]\t Batch Loss: 0.064110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation set: Average loss: 0.0385, Accuracy: 9875/10000 (99%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-r7nVjR476Z:\n",
      "Validation set: Average loss: 0.0385, Accuracy: 9875/10000 (99%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 9 [0/60000 samples (0%)]\t Batch Loss: 0.140912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-r7nVjR476Z:log: Train Epoch: 9 [0/60000 samples (0%)]\t Batch Loss: 0.140912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 9 [12800/60000 samples (21%)]\t Batch Loss: 0.109008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-r7nVjR476Z:log: Train Epoch: 9 [12800/60000 samples (21%)]\t Batch Loss: 0.109008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 9 [25600/60000 samples (43%)]\t Batch Loss: 0.252322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-r7nVjR476Z:log: Train Epoch: 9 [25600/60000 samples (43%)]\t Batch Loss: 0.252322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 9 [38400/60000 samples (64%)]\t Batch Loss: 0.272315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-r7nVjR476Z:log: Train Epoch: 9 [38400/60000 samples (64%)]\t Batch Loss: 0.272315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 9 [51200/60000 samples (85%)]\t Batch Loss: 0.178986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-r7nVjR476Z:log: Train Epoch: 9 [51200/60000 samples (85%)]\t Batch Loss: 0.178986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation set: Average loss: 0.0494, Accuracy: 9856/10000 (99%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-r7nVjR476Z:\n",
      "Validation set: Average loss: 0.0494, Accuracy: 9856/10000 (99%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete.\n",
      "Experiment ended. Checkpoints stored =)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-r7nVjR476Z:Experiment ended. Checkpoints stored =)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment ended.\n"
     ]
    }
   ],
   "source": [
    "exp.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "last_experiment = 'experiment_dir/' + sorted([d for d in os.listdir('experiment_dir/') if '20' in str(d)], reverse=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m20191011-112901_experiment\u001b[m\u001b[m \u001b[34mdata\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "!ls experiment_dir/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resuming an Experiment\n",
    "Let's now resume the last Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'experiment_dir/20191011-112901_experiment'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Setting up a new session...\n"
     ]
    }
   ],
   "source": [
    "from trixi.experiment import PytorchExperiment\n",
    "exp_resume = MNIST_experiment(config=c, name='resume_experiment', \n",
    "                              n_epochs=5, seed=42, base_dir='./experiment_dir', \n",
    "                              resume=last_experiment, resume_save_types=('model',\n",
    "                                                                         'simple',\n",
    "                                                                         'th_vars',\n",
    "                                                                         'results'), loggers={\"visdom\":\"visdom\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-GRQr9Zu7vY:Config:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"base_dir\": \"./experiment_dir\",\n",
      "    \"batch_size\": 64,\n",
      "    \"batch_size_test\": 1000,\n",
      "    \"learning_rate\": 0.01,\n",
      "    \"log_interval\": 200,\n",
      "    \"momentum\": 0.9,\n",
      "    \"n_epochs\": 10,\n",
      "    \"name\": \"experiment\",\n",
      "    \"rnd_seed\": 1,\n",
      "    \"seed\": 42,\n",
      "    \"use_cuda\": false\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-GRQr9Zu7vY:{\n",
      "    \"base_dir\": \"./experiment_dir\",\n",
      "    \"batch_size\": 64,\n",
      "    \"batch_size_test\": 1000,\n",
      "    \"learning_rate\": 0.01,\n",
      "    \"log_interval\": 200,\n",
      "    \"momentum\": 0.9,\n",
      "    \"n_epochs\": 10,\n",
      "    \"name\": \"experiment\",\n",
      "    \"rnd_seed\": 1,\n",
      "    \"seed\": 42,\n",
      "    \"use_cuda\": false\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment set up.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gkoehler/Anaconda-Envs/trixi_dev/trixi/trixi/logger/visdom/pytorchvisdomlogger.py:286: UserWarning: Could not render model, make sure the Graphviz executables are on your system.\n",
      "  warnings.warn(\"Could not render model, make sure the Graphviz executables are on your system.\")\n",
      "INFO:default-GRQr9Zu7vY:Experiment set up.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded existing config from: experiment_dir/20191011-112901_experiment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-GRQr9Zu7vY:Loaded existing config from: experiment_dir/20191011-112901_experiment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded existing checkpoint from: experiment_dir/20191011-112901_experiment/checkpoint/checkpoint_current.pth.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-GRQr9Zu7vY:Loaded existing checkpoint from: experiment_dir/20191011-112901_experiment/checkpoint/checkpoint_current.pth.tar\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gkoehler/Anaconda-Envs/trixi_dev/trixi/trixi/experiment/pytorchexperiment.py:830: UserWarning: label in add_result is deprecated, please use tag instead\n",
      "  warnings.warn(\"label in add_result is deprecated, please use tag instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 0 [0/60000 samples (0%)]\t Batch Loss: 0.062482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-GRQr9Zu7vY:log: Train Epoch: 0 [0/60000 samples (0%)]\t Batch Loss: 0.062482\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 0 [12800/60000 samples (21%)]\t Batch Loss: 0.178072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-GRQr9Zu7vY:log: Train Epoch: 0 [12800/60000 samples (21%)]\t Batch Loss: 0.178072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 0 [25600/60000 samples (43%)]\t Batch Loss: 0.069868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-GRQr9Zu7vY:log: Train Epoch: 0 [25600/60000 samples (43%)]\t Batch Loss: 0.069868\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 0 [38400/60000 samples (64%)]\t Batch Loss: 0.138978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-GRQr9Zu7vY:log: Train Epoch: 0 [38400/60000 samples (64%)]\t Batch Loss: 0.138978\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 0 [51200/60000 samples (85%)]\t Batch Loss: 0.037943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-GRQr9Zu7vY:log: Train Epoch: 0 [51200/60000 samples (85%)]\t Batch Loss: 0.037943\n",
      "/anaconda3/envs/trixi_dev/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation set: Average loss: 0.0429, Accuracy: 9864/10000 (99%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-GRQr9Zu7vY:\n",
      "Validation set: Average loss: 0.0429, Accuracy: 9864/10000 (99%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 1 [0/60000 samples (0%)]\t Batch Loss: 0.129980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-GRQr9Zu7vY:log: Train Epoch: 1 [0/60000 samples (0%)]\t Batch Loss: 0.129980\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 1 [12800/60000 samples (21%)]\t Batch Loss: 0.043514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-GRQr9Zu7vY:log: Train Epoch: 1 [12800/60000 samples (21%)]\t Batch Loss: 0.043514\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 1 [25600/60000 samples (43%)]\t Batch Loss: 0.120307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-GRQr9Zu7vY:log: Train Epoch: 1 [25600/60000 samples (43%)]\t Batch Loss: 0.120307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 1 [38400/60000 samples (64%)]\t Batch Loss: 0.092876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-GRQr9Zu7vY:log: Train Epoch: 1 [38400/60000 samples (64%)]\t Batch Loss: 0.092876\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 1 [51200/60000 samples (85%)]\t Batch Loss: 0.220384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-GRQr9Zu7vY:log: Train Epoch: 1 [51200/60000 samples (85%)]\t Batch Loss: 0.220384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation set: Average loss: 0.0375, Accuracy: 9881/10000 (99%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-GRQr9Zu7vY:\n",
      "Validation set: Average loss: 0.0375, Accuracy: 9881/10000 (99%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 2 [0/60000 samples (0%)]\t Batch Loss: 0.282830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-GRQr9Zu7vY:log: Train Epoch: 2 [0/60000 samples (0%)]\t Batch Loss: 0.282830\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 2 [12800/60000 samples (21%)]\t Batch Loss: 0.116380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-GRQr9Zu7vY:log: Train Epoch: 2 [12800/60000 samples (21%)]\t Batch Loss: 0.116380\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 2 [25600/60000 samples (43%)]\t Batch Loss: 0.086649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-GRQr9Zu7vY:log: Train Epoch: 2 [25600/60000 samples (43%)]\t Batch Loss: 0.086649\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 2 [38400/60000 samples (64%)]\t Batch Loss: 0.070201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-GRQr9Zu7vY:log: Train Epoch: 2 [38400/60000 samples (64%)]\t Batch Loss: 0.070201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 2 [51200/60000 samples (85%)]\t Batch Loss: 0.137666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-GRQr9Zu7vY:log: Train Epoch: 2 [51200/60000 samples (85%)]\t Batch Loss: 0.137666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation set: Average loss: 0.0393, Accuracy: 9876/10000 (99%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-GRQr9Zu7vY:\n",
      "Validation set: Average loss: 0.0393, Accuracy: 9876/10000 (99%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 3 [0/60000 samples (0%)]\t Batch Loss: 0.183245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-GRQr9Zu7vY:log: Train Epoch: 3 [0/60000 samples (0%)]\t Batch Loss: 0.183245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 3 [12800/60000 samples (21%)]\t Batch Loss: 0.125404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-GRQr9Zu7vY:log: Train Epoch: 3 [12800/60000 samples (21%)]\t Batch Loss: 0.125404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 3 [25600/60000 samples (43%)]\t Batch Loss: 0.247815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-GRQr9Zu7vY:log: Train Epoch: 3 [25600/60000 samples (43%)]\t Batch Loss: 0.247815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 3 [38400/60000 samples (64%)]\t Batch Loss: 0.090551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-GRQr9Zu7vY:log: Train Epoch: 3 [38400/60000 samples (64%)]\t Batch Loss: 0.090551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 3 [51200/60000 samples (85%)]\t Batch Loss: 0.083590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-GRQr9Zu7vY:log: Train Epoch: 3 [51200/60000 samples (85%)]\t Batch Loss: 0.083590\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation set: Average loss: 0.0401, Accuracy: 9882/10000 (99%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-GRQr9Zu7vY:\n",
      "Validation set: Average loss: 0.0401, Accuracy: 9882/10000 (99%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 4 [0/60000 samples (0%)]\t Batch Loss: 0.205364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-GRQr9Zu7vY:log: Train Epoch: 4 [0/60000 samples (0%)]\t Batch Loss: 0.205364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 4 [12800/60000 samples (21%)]\t Batch Loss: 0.071062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-GRQr9Zu7vY:log: Train Epoch: 4 [12800/60000 samples (21%)]\t Batch Loss: 0.071062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 4 [25600/60000 samples (43%)]\t Batch Loss: 0.149483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-GRQr9Zu7vY:log: Train Epoch: 4 [25600/60000 samples (43%)]\t Batch Loss: 0.149483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 4 [38400/60000 samples (64%)]\t Batch Loss: 0.079324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-GRQr9Zu7vY:log: Train Epoch: 4 [38400/60000 samples (64%)]\t Batch Loss: 0.079324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 4 [51200/60000 samples (85%)]\t Batch Loss: 0.075538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-GRQr9Zu7vY:log: Train Epoch: 4 [51200/60000 samples (85%)]\t Batch Loss: 0.075538\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation set: Average loss: 0.0380, Accuracy: 9886/10000 (99%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-GRQr9Zu7vY:\n",
      "Validation set: Average loss: 0.0380, Accuracy: 9886/10000 (99%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 5 [0/60000 samples (0%)]\t Batch Loss: 0.188546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-GRQr9Zu7vY:log: Train Epoch: 5 [0/60000 samples (0%)]\t Batch Loss: 0.188546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 5 [12800/60000 samples (21%)]\t Batch Loss: 0.078542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-GRQr9Zu7vY:log: Train Epoch: 5 [12800/60000 samples (21%)]\t Batch Loss: 0.078542\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 5 [25600/60000 samples (43%)]\t Batch Loss: 0.161435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-GRQr9Zu7vY:log: Train Epoch: 5 [25600/60000 samples (43%)]\t Batch Loss: 0.161435\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 5 [38400/60000 samples (64%)]\t Batch Loss: 0.083216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-GRQr9Zu7vY:log: Train Epoch: 5 [38400/60000 samples (64%)]\t Batch Loss: 0.083216\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 5 [51200/60000 samples (85%)]\t Batch Loss: 0.096535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-GRQr9Zu7vY:log: Train Epoch: 5 [51200/60000 samples (85%)]\t Batch Loss: 0.096535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation set: Average loss: 0.0358, Accuracy: 9886/10000 (99%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-GRQr9Zu7vY:\n",
      "Validation set: Average loss: 0.0358, Accuracy: 9886/10000 (99%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 6 [0/60000 samples (0%)]\t Batch Loss: 0.130948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-GRQr9Zu7vY:log: Train Epoch: 6 [0/60000 samples (0%)]\t Batch Loss: 0.130948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 6 [12800/60000 samples (21%)]\t Batch Loss: 0.262778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-GRQr9Zu7vY:log: Train Epoch: 6 [12800/60000 samples (21%)]\t Batch Loss: 0.262778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 6 [25600/60000 samples (43%)]\t Batch Loss: 0.136127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-GRQr9Zu7vY:log: Train Epoch: 6 [25600/60000 samples (43%)]\t Batch Loss: 0.136127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 6 [38400/60000 samples (64%)]\t Batch Loss: 0.102463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-GRQr9Zu7vY:log: Train Epoch: 6 [38400/60000 samples (64%)]\t Batch Loss: 0.102463\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 6 [51200/60000 samples (85%)]\t Batch Loss: 0.309935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-GRQr9Zu7vY:log: Train Epoch: 6 [51200/60000 samples (85%)]\t Batch Loss: 0.309935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation set: Average loss: 0.0364, Accuracy: 9882/10000 (99%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-GRQr9Zu7vY:\n",
      "Validation set: Average loss: 0.0364, Accuracy: 9882/10000 (99%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 7 [0/60000 samples (0%)]\t Batch Loss: 0.075785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-GRQr9Zu7vY:log: Train Epoch: 7 [0/60000 samples (0%)]\t Batch Loss: 0.075785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 7 [12800/60000 samples (21%)]\t Batch Loss: 0.109028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-GRQr9Zu7vY:log: Train Epoch: 7 [12800/60000 samples (21%)]\t Batch Loss: 0.109028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 7 [25600/60000 samples (43%)]\t Batch Loss: 0.063682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-GRQr9Zu7vY:log: Train Epoch: 7 [25600/60000 samples (43%)]\t Batch Loss: 0.063682\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 7 [38400/60000 samples (64%)]\t Batch Loss: 0.207931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-GRQr9Zu7vY:log: Train Epoch: 7 [38400/60000 samples (64%)]\t Batch Loss: 0.207931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 7 [51200/60000 samples (85%)]\t Batch Loss: 0.081487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-GRQr9Zu7vY:log: Train Epoch: 7 [51200/60000 samples (85%)]\t Batch Loss: 0.081487\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation set: Average loss: 0.0417, Accuracy: 9881/10000 (99%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-GRQr9Zu7vY:\n",
      "Validation set: Average loss: 0.0417, Accuracy: 9881/10000 (99%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 8 [0/60000 samples (0%)]\t Batch Loss: 0.103619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-GRQr9Zu7vY:log: Train Epoch: 8 [0/60000 samples (0%)]\t Batch Loss: 0.103619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 8 [12800/60000 samples (21%)]\t Batch Loss: 0.151205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-GRQr9Zu7vY:log: Train Epoch: 8 [12800/60000 samples (21%)]\t Batch Loss: 0.151205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 8 [25600/60000 samples (43%)]\t Batch Loss: 0.069670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-GRQr9Zu7vY:log: Train Epoch: 8 [25600/60000 samples (43%)]\t Batch Loss: 0.069670\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 8 [38400/60000 samples (64%)]\t Batch Loss: 0.017852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-GRQr9Zu7vY:log: Train Epoch: 8 [38400/60000 samples (64%)]\t Batch Loss: 0.017852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 8 [51200/60000 samples (85%)]\t Batch Loss: 0.160655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-GRQr9Zu7vY:log: Train Epoch: 8 [51200/60000 samples (85%)]\t Batch Loss: 0.160655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation set: Average loss: 0.0359, Accuracy: 9883/10000 (99%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-GRQr9Zu7vY:\n",
      "Validation set: Average loss: 0.0359, Accuracy: 9883/10000 (99%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 9 [0/60000 samples (0%)]\t Batch Loss: 0.059812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-GRQr9Zu7vY:log: Train Epoch: 9 [0/60000 samples (0%)]\t Batch Loss: 0.059812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 9 [12800/60000 samples (21%)]\t Batch Loss: 0.079527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-GRQr9Zu7vY:log: Train Epoch: 9 [12800/60000 samples (21%)]\t Batch Loss: 0.079527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 9 [25600/60000 samples (43%)]\t Batch Loss: 0.133482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-GRQr9Zu7vY:log: Train Epoch: 9 [25600/60000 samples (43%)]\t Batch Loss: 0.133482\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 9 [38400/60000 samples (64%)]\t Batch Loss: 0.219746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-GRQr9Zu7vY:log: Train Epoch: 9 [38400/60000 samples (64%)]\t Batch Loss: 0.219746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: Train Epoch: 9 [51200/60000 samples (85%)]\t Batch Loss: 0.262169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-GRQr9Zu7vY:log: Train Epoch: 9 [51200/60000 samples (85%)]\t Batch Loss: 0.262169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation set: Average loss: 0.0363, Accuracy: 9893/10000 (99%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-GRQr9Zu7vY:\n",
      "Validation set: Average loss: 0.0363, Accuracy: 9893/10000 (99%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete.\n",
      "Experiment ended. Checkpoints stored =)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:default-GRQr9Zu7vY:Experiment ended. Checkpoints stored =)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment ended.\n"
     ]
    }
   ],
   "source": [
    "exp_resume.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m20191011-112901_experiment\u001b[m\u001b[m        \u001b[34mdata\u001b[m\u001b[m\n",
      "\u001b[34m20191011-114503_resume_experiment\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "!ls experiment_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also change a parameter in your experiment and simply run the same experiment again (this can of course also be done automatically)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "c.learning_rate = 0.0001\n",
    "exp2 = MNIST_experiment(config=c, name='experiment2', n_epochs=c.n_epochs, \n",
    "                       seed=42, base_dir='./experiment_dir', loggers={\"visdom\":\"visdom\"})\n",
    "exp2.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets compare all our experiments. Therefore we simply start the trixi browser:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m trixi.browser $PWD/experiment_dir"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
